from __future__ import annotations
from abc import ABC, abstractmethod
from typing import Optional, TYPE_CHECKING, Tuple, Dict, Any
from enum import Enum, auto
from dataclasses import dataclass, asdict
from ...core.ops import Ops

if TYPE_CHECKING:
    from ...core.workpiece import WorkPiece


class CoordinateSystem(Enum):
    """
    Defines the geometric coordinate space in which an Ops object was
    generated.
    """

    PIXEL_SPACE = auto()
    """
    An intermediate coordinate system for raster-based operations.

    - **Unit**: Pixels.
    - **Origin (0,0)**: Top-left corner of the source bitmap surface.
    - **Use**: Used by producers that trace raster images. The
      `source_dimensions` will be the width and height of the bitmap
      in pixels.
    """

    MILLIMETER_SPACE = auto()
    """
    The canonical coordinate system for all local vector geometry.

    This is the standard space for `workpiece.vectors` and any scalable ops
    generated by a producer.

    - **Unit**: Millimeters (mm).
    - **Origin (0,0)**: The bottom-left corner anchor of the workpiece.
    - **Orientation**: Y-axis pointing upwards (a standard Cartesian system).
    - **Use**: This is the contract for importers and for producers that
      output scalable vector geometry (`is_scalable=True`). The
      `source_dimensions` will be the width and height of the workpiece's
      "canvas" in millimeters.
    """


@dataclass
class PipelineArtifact:
    """
    A self-describing container for the output of an OpsProducer.
    """

    #: The generated machine operations.
    ops: Ops

    #: **The Behavioral Contract**: A flag indicating if the ops can be
    #: mathematically scaled.
    #: - True: The Ops are resolution-independent vectors. On resize, the
    #:   OpsGenerator can perform a cheap, real-time `ops.scale()` transform.
    #: - False: The Ops are resolution-dependent (e.g., raster lines). On
    #:   resize, the OpsGenerator must trigger an expensive, full regeneration.
    is_scalable: bool

    #: **The Geometric Contract**: An enum describing the coordinate space in
    #: which the ops were generated, primarily defining the origin.
    source_coordinate_system: CoordinateSystem

    #: The dimensions (width, height) of the "canvas" the ops were generated
    #: for, in units corresponding to the `source_coordinate_system`.
    #: (e.g., pixels for PIXEL_SPACE, mm for the others). This is essential
    #: for calculating relative scale factors.
    source_dimensions: Optional[Tuple[float, float]] = None

    #: The authoritative physical size (width, height) of the workpiece at the
    #: moment generation was triggered. This is crucial for scalable vector ops
    #: to ensure the correct canvas size is used, even if the workpiece object
    #: passed to the producer has had its own `.size` property modified.
    generation_size: Optional[Tuple[float, float]] = None

    def to_dict(self) -> Dict[str, Any]:
        """
        Serializes the artifact to a dictionary for inter-process transfer.
        """
        data = asdict(self)
        data["ops"] = self.ops.to_dict()
        data["source_coordinate_system"] = self.source_coordinate_system.name
        return data

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "PipelineArtifact":
        """Deserializes a dictionary back into a PipelineArtifact instance."""
        return cls(
            ops=Ops.from_dict(data["ops"]),
            is_scalable=data["is_scalable"],
            source_coordinate_system=CoordinateSystem[
                data["source_coordinate_system"]
            ],
            source_dimensions=tuple(data["source_dimensions"])
            if data["source_dimensions"]
            else None,
            generation_size=tuple(data["generation_size"])
            if data["generation_size"]
            else None,
        )


class OpsProducer(ABC):
    """
    Given a Cairo surface, an OpsProducer outputs an Ops object.
    Examples may include:

    - Tracing a bitmap to produce a path (Ops object).
    - Reading vector data from an image to turn it into Ops.
    """

    @abstractmethod
    def run(
        self,
        laser,
        surface,
        pixels_per_mm,
        *,
        workpiece: "Optional[WorkPiece]" = None,
        y_offset_mm: float = 0.0,
    ) -> PipelineArtifact:
        pass

    def is_vector_producer(self) -> bool:
        """
        Specifies the generation strategy for the producer.

        - True: Use the vector/full-render path. The producer can handle
          vector inputs directly, or it traces a single, fully-rendered
          raster image.
        - False: Use the chunked raster path. The producer requires the
          input to be rendered and fed to it in horizontal strips.

        This controls the *process* of generation, while the artifact's
        `is_scalable` flag controls the caching behavior of the *product*.
        """
        return True

    @property
    def requires_full_render(self) -> bool:
        """
        Returns True if a producer requires the entire workpiece to be
        rendered into a single surface, even if its output is scalable.
        This is essential for algorithms that need a global view of the image,
        like hulling, and forces the pipeline to provide a raster input.
        """
        return False

    def to_dict(self) -> dict:
        """
        Serializes the producer configuration to a dictionary.

        This dictionary can be used with `OpsProducer.from_dict` to
        recreate the producer instance.
        """
        return {
            "type": self.__class__.__name__,
            "params": {},  # All current producers are stateless
        }

    @staticmethod
    def from_dict(data: dict):
        """
        Deserializes a producer from a dictionary.

        This is a factory method that looks up the producer class by its
        name from the central registry and instantiates it.
        """
        # Local import to avoid a circular dependency at module-load time.
        # The producer_by_name map is built in the package's __init__.py,
        # which imports this module.
        from . import producer_by_name

        producer_type = data.get("type")
        if not producer_type:
            raise ValueError("Input dictionary must contain a 'type' key.")

        ProducerClass = producer_by_name.get(producer_type)

        if not ProducerClass:
            raise ValueError(f"Unknown producer type: '{producer_type}'")

        # Instantiate the class with parameters from the dictionary.
        # This allows for future producers to have configurable state.
        params = data.get("params", {})
        return ProducerClass(**params)
